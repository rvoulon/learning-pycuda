{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Programming with Python - PyCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 device(s) found\n",
      "Device 0: Quadro P4000\n",
      "  Compute capability: 6.1\n",
      "  Total memory: 8308736.0 KB\n"
     ]
    }
   ],
   "source": [
    "print(f\"{cuda.Device.count()} device(s) found\")\n",
    "for i in range(cuda.Device.count()):\n",
    "    dev = cuda.Device(i)\n",
    "    print(f\"Device {i}: {dev.name()}\")\n",
    "    a, b = dev.compute_capability()\n",
    "    print(f\"  Compute capability: {a}.{b}\")\n",
    "    print(f\"  Total memory: {dev.total_memory() / 1024} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix * 2\n",
    "1. set up your data (array/vector, matrix) on the host, setting type to `np.float32`\n",
    "1. allocate space on the GPU's memory and copy the data to it (to device)\n",
    "1. write the key computational kernel for the GPU\n",
    "1. get the function and call it, give as parameters the pointer to your data on the GPU and the block size\n",
    "1. create a new variable to contain the data from the GPU and copy it (to host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.2237811 ,  1.7522274 ,  0.2198983 ,  0.6134487 , -0.8579877 ],\n",
       "       [ 0.22636674, -1.1725038 , -0.35058454, -0.97915286,  1.4445748 ],\n",
       "       [-0.41134974,  0.96850103,  1.0174406 , -0.41382772, -0.6064575 ],\n",
       "       [ 0.43275827,  0.06282279,  0.0935237 , -0.9783392 , -1.5713155 ],\n",
       "       [ 0.18036895, -1.4524317 ,  1.1295315 ,  0.38706082,  1.3106147 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Create a random matrix of 5x5 and convert to float32 for GPU architecture\"\"\"\n",
    "a = np.random.randn(5,5).astype(np.float32)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Allocate space on the GPU's memory and copy the data to it\"\"\"\n",
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Write the key computational kernel for the GPU, double the matrix given\"\"\"\n",
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void doubleMatrix(float *a) {\n",
    "        int idx = threadIdx.x + threadIdx.y * blockDim.x;\n",
    "        a[idx] *= 2;\n",
    "    }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "func = mod.get_function(\"doubleMatrix\")\n",
    "func(a_gpu, block=(5,5,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_doubled = np.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_doubled, a_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------- ORIGINAL MATRIX -------------\n",
      "[[-1.2237811   1.7522274   0.2198983   0.6134487  -0.8579877 ]\n",
      " [ 0.22636674 -1.1725038  -0.35058454 -0.97915286  1.4445748 ]\n",
      " [-0.41134974  0.96850103  1.0174406  -0.41382772 -0.6064575 ]\n",
      " [ 0.43275827  0.06282279  0.0935237  -0.9783392  -1.5713155 ]\n",
      " [ 0.18036895 -1.4524317   1.1295315   0.38706082  1.3106147 ]]\n",
      "---- DOUBLED MATRIX AFTER COMPUTATION -----\n",
      "[[-2.4475622   3.5044549   0.4397966   1.2268974  -1.7159754 ]\n",
      " [ 0.4527335  -2.3450077  -0.7011691  -1.9583057   2.8891497 ]\n",
      " [-0.8226995   1.9370021   2.034881   -0.82765543 -1.212915  ]\n",
      " [ 0.86551654  0.12564558  0.1870474  -1.9566784  -3.142631  ]\n",
      " [ 0.3607379  -2.9048634   2.259063    0.77412164  2.6212294 ]]\n"
     ]
    }
   ],
   "source": [
    "print(\"------------- ORIGINAL MATRIX -------------\")\n",
    "print(a)\n",
    "print(\"---- DOUBLED MATRIX AFTER COMPUTATION -----\")\n",
    "print(a_doubled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## An even easier introduction to CUDA\n",
    "https://devblogs.nvidia.com/even-easier-introduction-cuda/  \n",
    "Here's the code in C++, we'll need to port that to Python:\n",
    "\n",
    "```c++\n",
    "#include <iostream>\n",
    "#include <math.h>\n",
    "\n",
    "// function to add the elements of two arrays\n",
    "void add(int n, float *x, float *y)\n",
    "{\n",
    "  for (int i = 0; i < n; i++)\n",
    "      y[i] = x[i] + y[i];\n",
    "}\n",
    "\n",
    "int main(void)\n",
    "{\n",
    "  int N = 1<<20; // 1M elements\n",
    "\n",
    "  float *x = new float[N];\n",
    "  float *y = new float[N];\n",
    "\n",
    "  // initialize x and y arrays on the host\n",
    "  for (int i = 0; i < N; i++) {\n",
    "    x[i] = 1.0f;\n",
    "    y[i] = 2.0f;\n",
    "  }\n",
    "\n",
    "  // Run kernel on 1M elements on the CPU\n",
    "  add(N, x, y);\n",
    "\n",
    "  // Check for errors (all values should be 3.0f)\n",
    "  float maxError = 0.0f;\n",
    "  for (int i = 0; i < N; i++)\n",
    "    maxError = fmax(maxError, fabs(y[i]-3.0f));\n",
    "  std::cout << \"Max error: \" << maxError << std::endl;\n",
    "\n",
    "  // Free memory\n",
    "  delete [] x;\n",
    "  delete [] y;\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here's that same code in Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add(n, x, y):\n",
    "    \"\"\"Function to add the elements of two arrays\"\"\"\n",
    "    for i in range(0, n):\n",
    "        y[i] = x[i] + y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1<<20 # 1M elements\n",
    "x = np.ones(N, dtype=np.float32)\n",
    "y = np.full(N, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "add(N, x, y)\n",
    "print(f\"---- {time.time() - start} seconds ----\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "max_error = 0.0\n",
    "for i in range(0, N):\n",
    "    global max_error\n",
    "    max_error = max(max_error, (y[i] - 3.0))\n",
    "print(f\"Max error: {max_error}\")\n",
    "print(f\"---- {time.time() - start} seconds ----\")\n",
    "\n",
    "x = []\n",
    "y = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now let's get this running on the GPU\n",
    "1. set up your data (array/vector, matrix) on the host, setting type to `np.float32`\n",
    "1. allocate space on the GPU's memory and copy the data to it (to device)\n",
    "1. write the key computational kernel for the GPU\n",
    "1. get the function and call it, give as parameters the pointer to your data on the GPU and the block size\n",
    "1. synchronize with the device: wait for GPU to finish before accessing on host\n",
    "1. create a new variable to contain the data from the GPU and copy it (to host)\n",
    "1. free up the memory on the device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1<<20 # 1M elements\n",
    "x = np.ones(N, dtype=np.float32)\n",
    "y = np.full(N, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gpu = cuda.mem_alloc(x.nbytes)\n",
    "y_gpu = cuda.mem_alloc(y.nbytes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cuda.memcpy_htod(x_gpu, x)\n",
    "cuda.memcpy_htod(y_gpu, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void add(float *x, float *y)\n",
    "    {\n",
    "        int n = 1<<20;\n",
    "        for (int i = 0; i < n; i++)\n",
    "            y[i] = x[i] + y[i];\n",
    "    }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---- 0.2184922695159912 seconds ----\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<function DeviceAllocation.free>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start = time.time()\n",
    "func = mod.get_function(\"add\")\n",
    "func(x_gpu, y_gpu, block=(1, 1, 1))\n",
    "y_added = np.empty_like(y)\n",
    "cuda.memcpy_dtoh(y_added, y_gpu)\n",
    "print(f\"---- {time.time() - start} seconds ----\")\n",
    "\n",
    "cuda.DeviceAllocation.free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max error: 4.674736414298997e+18\n",
      "---- 2.9716413021087646 seconds ----\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "max_error = 0.0\n",
    "for i in range(0, N):\n",
    "    global max_error\n",
    "    max_error = max(max_error, (y_added[i] - 3.0))\n",
    "print(f\"Max error: {max_error}\")\n",
    "print(f\"---- {time.time() - start} seconds ----\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ZOMG! It worked! ðŸ™€ðŸ™€ðŸ™€\n",
    "Alright, now let's use multiple threads!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
