{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPU Programming with Python - PyCUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pycuda.driver as cuda\n",
    "import pycuda.autoinit\n",
    "from pycuda.compiler import SourceModule\n",
    "from pycuda import gpuarray\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test it out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{cuda.Device.count()} device(s) found\")\n",
    "for i in range(cuda.Device.count()):\n",
    "    dev = cuda.Device(i)\n",
    "    print(f\"Device {i}: {dev.name()}\")\n",
    "    a, b = dev.compute_capability()\n",
    "    print(f\"  Compute capability: {a}.{b}\")\n",
    "    print(f\"  Total memory: {dev.total_memory() / 1024} KB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix * 2\n",
    "1. set up your data (array/vector, matrix) on the host, setting type to `np.float32`\n",
    "1. allocate space on the GPU's memory and copy the data to it (to device)\n",
    "1. write the key computational kernel for the GPU\n",
    "1. get the function and call it, give as parameters the pointer to your data on the GPU and the block size\n",
    "1. create a new variable to contain the data from the GPU and copy it (to host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Create a random matrix of 5x5 and convert to float32 for GPU architecture\"\"\"\n",
    "a = np.random.randn(5,5).astype(np.float32)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Allocate space on the GPU's memory and copy the data to it\"\"\"\n",
    "a_gpu = cuda.mem_alloc(a.nbytes)\n",
    "cuda.memcpy_htod(a_gpu, a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\"Write the key computational kernel for the GPU, double the matrix given\"\"\"\n",
    "mod = SourceModule(\"\"\"\n",
    "    __global__ void doubleMatrix(float *a) {\n",
    "        int idx = threadIdx.x + threadIdx.y * blockDim.x;\n",
    "        a[idx] *= 2;\n",
    "    }\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "starttime = time.time()\n",
    "func = mod.get_function(\"doubleMatrix\")\n",
    "func(a_gpu, block=(5,5,1))\n",
    "print(f\"Time: {time.time() - starttime}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_doubled = np.empty_like(a)\n",
    "cuda.memcpy_dtoh(a_doubled, a_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"------------- ORIGINAL MATRIX -------------\")\n",
    "print(a)\n",
    "print(\"---- DOUBLED MATRIX AFTER COMPUTATION -----\")\n",
    "print(a_doubled)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dot product (matrix * matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
